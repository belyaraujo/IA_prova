{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHZ7GhqoRjDX",
        "outputId": "3ec95853-5165-4bcc-cea2-ea00babe018d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install roboflow"
      ],
      "metadata": {
        "id": "sY18JozXEgeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ8XhrXLNbxB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import cv2\n",
        "from roboflow import Roboflow\n",
        "import os\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = '/content/drive/MyDrive/Inteligência artificial/CBIS-DDSM'"
      ],
      "metadata": {
        "id": "5ni1suWtSGJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicom_data = pd.read_csv(dataset + '/csv/dicom_info.csv')"
      ],
      "metadata": {
        "id": "Q83hTSK_zVcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calcificações"
      ],
      "metadata": {
        "id": "WdjpgwSXzeS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# patient_id, abnormality type, calc type, pathology, image file path\n",
        "\n",
        "calc_case_description_train_set = pd.read_csv(dataset + '/csv/calc_case_description_train_set.csv',\n",
        "                                              header=0,\n",
        "                                              usecols=[\"patient_id\", \"abnormality type\", \"calc type\", \"pathology\", \"image file path\"])\n",
        "\n",
        "calc_case_description_test_set = pd.read_csv(dataset + '/csv/calc_case_description_test_set.csv',\n",
        "                                             header=0,\n",
        "                                             usecols=[\"patient_id\", \"abnormality type\", \"calc type\", \"pathology\", \"image file path\"])\n"
      ],
      "metadata": {
        "id": "k70UdyK7m5jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Massas"
      ],
      "metadata": {
        "id": "O_q8J5iRzkE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# patient_id, abnormality type, mass shape, pathology, image file path\n",
        "\n",
        "mass_case_description_train_set = pd.read_csv(dataset + '/csv/mass_case_description_test_set.csv',\n",
        "                                              header=0,\n",
        "                                              usecols=[\"patient_id\", \"abnormality type\", \"mass shape\", \"pathology\", \"image file path\"])\n",
        "\n",
        "mass_case_description_test_set = pd.read_csv(dataset + '/csv/mass_case_description_test_set.csv',\n",
        "                                                                                           header=0,\n",
        "                                              usecols=[\"patient_id\", \"abnormality type\", \"mass shape\", \"pathology\", \"image file path\"])\n"
      ],
      "metadata": {
        "id": "DmbIpkzUzptH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def alterar_nome_da_pasta(nome):\n",
        "  teste = \"Mass-Test_P_00017_LEFT_CC/1.3.6.1.4.1.9590.100.1.2.289610447411344525237308079592285912683/1.3.6.1.4.1.9590.100.1.2.22131189612893294827907969600765582967/000000.dcm\"\n",
        "\n",
        "  padrao = r'.*?/.*?/(?P<string>.*?)/'\n",
        "  resultado = re.search(padrao, nome)\n",
        "\n",
        "  string_desejada = resultado.group('string')\n",
        "  string_desejada = dataset + '/jpeg/' + string_desejada\n",
        "  # print(string_desejada)\n",
        "\n",
        "  return string_desejada"
      ],
      "metadata": {
        "id": "tG4VJ9SslqkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mass_case_description_train_set.head())\n",
        "print(mass_case_description_train_set.describe())\n",
        "print(mass_case_description_train_set['pathology'].value_counts())\n",
        "print(mass_case_description_train_set['image file path'])"
      ],
      "metadata": {
        "id": "Cq82ZvEDl8Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alterando o caminho das pastas"
      ],
      "metadata": {
        "id": "zcWnczQTnDCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calc_case_description_train_set['image file path'] = mass_case_description_train_set['image file path'].apply(alterar_nome_da_pasta)\n",
        "\n",
        "calc_case_description_test_set['image file path'] = mass_case_description_train_set['image file path'].apply(alterar_nome_da_pasta)\n",
        "\n",
        "mass_case_description_train_set['image file path'] = mass_case_description_train_set['image file path'].apply(alterar_nome_da_pasta)\n",
        "\n",
        "mass_case_description_test_set['image file path'] = mass_case_description_test_set['image file path'].apply(alterar_nome_da_pasta)\n"
      ],
      "metadata": {
        "id": "W7P1yX7l3TCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mass_case_description_train_set['image file path'])"
      ],
      "metadata": {
        "id": "DJiQOhIWl-6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cria o ROI"
      ],
      "metadata": {
        "id": "ojb4BUZot8_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def obter_nomes_imagens(diretorio, extensoes=['*.jpg']):\n",
        "    caminho_completo = os.path.join(diretorio, '*')\n",
        "    nomes_imagens = []\n",
        "\n",
        "    for extensao in extensoes:\n",
        "        caminho_imagens = os.path.join(diretorio, extensao)\n",
        "        nomes_imagens.extend(glob.glob(caminho_imagens))\n",
        "\n",
        "    nomes_imagens = [os.path.basename(imagem) for imagem in nomes_imagens]\n",
        "    return nomes_imagens\n",
        "\n",
        "def cortar_imagem(nome_pasta):\n",
        "    rf = Roboflow(api_key=\"CEfThkqYjDhVzpzg2wJO\")\n",
        "    project = rf.workspace().project(\"breast-cancer-roi-n4ssp\")\n",
        "    model = project.version(1).model\n",
        "\n",
        "    # print(model.predict(\"/content/1-126.jpg\", confidence=50, overlap=50).json())\n",
        "\n",
        "    nome_pasta = dataset + '/jpeg/' + nome_pasta\n",
        "    nomes_imagens = obter_nomes_imagens(nome_pasta)\n",
        "\n",
        "    prediction = model.predict(nome_pasta + '/' + nomes_imagens[0], confidence=50, overlap=50).json()\n",
        "    prediction_list = prediction[\"predictions\"]\n",
        "    prediction_dict = prediction_list[0]\n",
        "\n",
        "    roi_x = int(prediction_dict['x'] - prediction_dict['width'] / 2)\n",
        "    roi_y = int(prediction_dict['y'] - prediction_dict['height'] / 2)\n",
        "    roi_width = int(prediction_dict['width'])\n",
        "    roi_height = int(prediction_dict['height'])\n",
        "\n",
        "    image = cv2.imread(nome_pasta + '/' + nomes_imagens[0])\n",
        "\n",
        "    roi = image[roi_y:roi_y+roi_height, roi_x:roi_x+roi_width]\n",
        "    # print(roi)\n",
        "\n",
        "    cv2.imwrite(nome_pasta + \"/roi_\" + nomes_imagens[0], roi)\n",
        "\n",
        "# falta chamar essa função para todas as pastas de treinamento e teste\n",
        "# nome_pasta = '1.3.6.1.4.1.9590.100.1.2.126082211045731020508108042042916052'\n",
        "# cortar_imagem(nome_pasta)"
      ],
      "metadata": {
        "id": "cKx_GB-zx64O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(calc_case_description_train_set.head())\n",
        "print(mass_case_description_train_set.head())"
      ],
      "metadata": {
        "id": "lvpfKxI4a0_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN\n",
        "\n",
        "# calc type\n",
        "train_calc = calc_case_description_train_set.drop('calc type', axis=1)\n",
        "# mass shape\n",
        "train_mass = mass_case_description_train_set.drop('mass shape', axis=1)\n",
        "\n",
        "\n",
        "# Merge df?\n",
        "# train = pd.merge(train_calc , train_mass, how = 'outer')\n",
        "test = pd.merge(calc_case_description_test_set, mass_case_description_test_set, how = 'outer')\n",
        "\n",
        "# ------------------------------------\n",
        "\n",
        "train = pd.concat([train_calc, # train = pd.merge(train_calc , train_mass, how = 'outer')\n",
        "], axis=0)\n",
        "\n",
        "# Reinicializar os índices do DataFrame resultante\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# ------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "# train['image file path'].value_counts()\n",
        "# train.head()\n",
        "# train['abnormality type'].value_counts()\n",
        "\n",
        "# Use o método dropna para excluir os valores NaN da coluna 'image file path'\n",
        "train = train.dropna(subset=['image file path'])\n",
        "\n",
        "# convertendo para string\n",
        "train['image file path'] = train['image file path'].astype(str)\n",
        "\n",
        "# img_width, img_height = 150, 150\n",
        "img_width, img_height = 2936, 4216\n",
        "#2.936 x 4.216\n",
        "\n",
        "class_names = ['calcification', 'mass']\n",
        "\n",
        "# Tamanho do lote de treinamento\n",
        "batch_size = 32\n",
        "# Caminho para o diretório raiz das imagens\n",
        "nome_pasta_root = dataset + '/jpeg/'\n",
        "\n",
        "# ImageDataGenerator para pré-processar as imagens\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,  # Normaliza os valores dos pixels para o intervalo [0, 1]\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train,\n",
        "    x_col='image file path',\n",
        "    y_col='abnormality type',  # Coluna que contém os rótulos das categorias (mass ou calcification)\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',  # Classificação binária\n",
        "    classes=['mass', 'calcification'],  # Nomes das classes\n",
        "    directory=nome_pasta_root\n",
        ")\n",
        "\n",
        "# Montar as camadas do modelo\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(img_width, img_height)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid') # Camada de saída com ativação sigmóide para classificação binária\n",
        "    # keras.layers.Dense(2, activation='softmax') # 2 categorias (calcification, mass)\n",
        "\n",
        "])\n",
        "\n",
        "# Compilar o modelo\n",
        "# loss='sparse_categorical_crossentropy',\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs = 2  # Número de épocas de treinamento\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "gjyhIujlD60q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.head())\n",
        "\n",
        "print(train['abnormality type'].value_counts())\n",
        "\n",
        "print(train['image file path'].value_counts())\n",
        "\n",
        "print(test.head())\n",
        "\n",
        "print(type(train['abnormality type'].value_counts()))\n",
        "\n",
        "print(train['abnormality type'].value_counts())\n",
        "\n",
        "print(test['abnormality type'].value_counts())\n",
        "\n",
        "print(type(train['image file path']))"
      ],
      "metadata": {
        "id": "gphLJuVWGb-V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}